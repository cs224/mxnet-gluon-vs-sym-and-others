{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christian Schuhegger \n",
      "last updated: 2019-02-26 \n",
      "\n",
      "CPython 3.6.8\n",
      "IPython 7.3.0\n",
      "\n",
      "numpy 1.14.6\n",
      "scipy 1.2.0\n",
      "pandas 0.24.1\n",
      "matplotlib 3.0.2\n",
      "seaborn 0.9.0\n",
      "mxnet 1.3.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Christian Schuhegger' -u -d -v -p numpy,scipy,pandas,matplotlib,seaborn,mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, scipy, scipy.stats as stats, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import sklearn, sklearn.pipeline, sklearn.model_selection, sklearn.preprocessing\n",
    "import logging, time, datetime, tqdm\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, autograd, metric\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "# pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "np.set_printoptions(edgeitems=10)\n",
    "np.set_printoptions(linewidth=1000)\n",
    "np.set_printoptions(suppress=True)\n",
    "np.core.arrayprint._line_width = 180\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "from IPython.display import display_html\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        if type(df) == np.ndarray:\n",
    "            df = pd.DataFrame(df)\n",
    "        html_str+=df.to_html()\n",
    "    html_str = html_str.replace('table','table style=\"display:inline\"')\n",
    "    # print(html_str)\n",
    "    display_html(html_str,raw=True)\n",
    "\n",
    "CSS = \"\"\"\n",
    ".output {\n",
    "    flex-direction: row;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def display_graphs_side_by_side(*args):\n",
    "    html_str='<table><tr>'\n",
    "    for g in args:\n",
    "        html_str += '<td>'\n",
    "        html_str += g._repr_svg_()\n",
    "        html_str += '</td>'\n",
    "    html_str += '</tr></table>'\n",
    "    display_html(html_str,raw=True)\n",
    "    \n",
    "\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s:%(name)s:%(levelname)s: %(message)s')\n",
    "log = logging.getLogger('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_in       = 1000\n",
    "N_subjects = 260 * 10 # 100000\n",
    "N_subjects = 100000\n",
    "W = stats.norm(loc=0, scale=1).rvs(size=(2,N_in), random_state=np.random.RandomState(42))\n",
    "X = stats.norm(loc=0, scale=1).rvs(size=(N_subjects,N_in), random_state=np.random.RandomState(43))\n",
    "y = np.sum(W[1:,:] * X + W[0,:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000,), (100000, 1000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100000.000000\n",
       "mean         19.234805\n",
       "std          31.516783\n",
       "min        -147.380827\n",
       "25%          -2.102370\n",
       "50%          19.273695\n",
       "75%          40.475011\n",
       "max         147.253509\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gluon_iter(x_in, y_in, batch_size=256):\n",
    "    x_nd = nd.array(x_in)\n",
    "    y_nd = nd.array(y_in)\n",
    "    dataset = mx.gluon.data.ArrayDataset(x_nd, y_nd)\n",
    "\n",
    "    itr = mx.gluon.data.DataLoader(dataset, batch_size = batch_size, shuffle = None)# , last_batch = 'rollover'\n",
    "    return itr\n",
    "\n",
    "def to_sym_iter(x_in, y_in, batch_size=256):\n",
    "    itr = mx.io.NDArrayIter(x_in, y_in, batch_size, shuffle=None , label_name='lin_reg_label')\n",
    "    return itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "gluon_train_iter = to_gluon_iter(X_train, y_train, batch_size=batch_size)\n",
    "gluon_valid_iter = to_gluon_iter(X_test , y_test, batch_size=batch_size)\n",
    "\n",
    "sym_train_iter = to_sym_iter(X_train, y_train, batch_size=batch_size)\n",
    "sym_valid_iter  = to_sym_iter(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aux():\n",
    "    epochs=20\n",
    "    model_ctx=mx.cpu()\n",
    "    loss_function = mx.gluon.loss.L2Loss()\n",
    "    init_function = mx.init.Xavier()\n",
    "    optimizer     = mx.optimizer.Adam()\n",
    "    return epochs, model_ctx, loss_function, init_function, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gluon_model():\n",
    "    ACTIVATION = 'relu'\n",
    "    net = mx.gluon.nn.HybridSequential(prefix='MLP_')\n",
    "    with net.name_scope():\n",
    "        net.add(\n",
    "            mx.gluon.nn.Dense(300, activation=ACTIVATION, prefix='fc-1_'),\n",
    "            mx.gluon.nn.Dense(100, activation=ACTIVATION, prefix='fc-2_'),\n",
    "            mx.gluon.nn.Dense(1 , activation=None       , prefix='predictions')\n",
    "        )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sym_model():\n",
    "    ACTIVATION = 'relu'\n",
    "\n",
    "    data = mx.sym.Variable('data')\n",
    "    Y    = mx.sym.Variable('lin_reg_label')\n",
    "    fc1  = mx.sym.FullyConnected(data, name='fc1', num_hidden=300)\n",
    "    act1 = mx.sym.Activation(fc1, name='relu1', act_type=ACTIVATION)\n",
    "    fc2  = mx.sym.FullyConnected(act1, name='fc2', num_hidden=100)\n",
    "    act2 = mx.sym.Activation(fc2, name='relu2', act_type=ACTIVATION)\n",
    "    fc3  = mx.sym.FullyConnected(act2, name='fc3', num_hidden=1)\n",
    "    lro  = mx.sym.LinearRegressionOutput(data=fc3, label=Y, name=\"lro\")\n",
    "    \n",
    "    return lro    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, model_ctx, loss_function, init_function, optimizer = create_aux()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3178329467773438, 0, 2.2013967]\n",
      "[4.722989320755005, 1, 0.59203905]\n",
      "[7.081446647644043, 2, 0.25728953]\n",
      "[9.515666484832764, 3, 0.1454216]\n",
      "[11.848104238510132, 4, 0.09439549]\n",
      "[14.207354307174683, 5, 0.07868443]\n",
      "[16.529359579086304, 6, 0.08771128]\n",
      "[18.900734901428223, 7, 0.20554832]\n",
      "[21.175779819488525, 8, 1.1770587]\n",
      "[23.751203298568726, 9, 3.5061474]\n",
      "[26.0213360786438, 10, 1.3041992]\n",
      "[28.45488739013672, 11, 1.2650495]\n",
      "[30.91821575164795, 12, 0.6886987]\n",
      "[33.28227782249451, 13, 0.6853665]\n",
      "[35.67546319961548, 14, 1.2785094]\n",
      "[37.99745440483093, 15, 2.0354834]\n",
      "[40.352094650268555, 16, 1.4828372]\n",
      "[42.69041466712952, 17, 3.3803318]\n",
      "[45.05994510650635, 18, 1.5223502]\n",
      "[47.434420585632324, 19, 4.2342873]\n"
     ]
    }
   ],
   "source": [
    "gluon_model = create_gluon_model()\n",
    "gluon_model.hybridize()\n",
    "gluon_model.collect_params().initialize(init_function, ctx=model_ctx)\n",
    "\n",
    "trainer = gluon.Trainer(gluon_model.collect_params(), optimizer)\n",
    "\n",
    "nr_batches = len(X_train) // batch_size\n",
    "total = epochs * (nr_batches + 1)\n",
    "\n",
    "time1 = time.time()\n",
    "for e in range(epochs):\n",
    "    for i, (x_, y_) in enumerate(gluon_train_iter):\n",
    "        x_ = x_.as_in_context(model_ctx)\n",
    "        y_ = y_.as_in_context(model_ctx)\n",
    "        with autograd.record():\n",
    "            output = gluon_model(x_)\n",
    "            loss = loss_function(output, y_)\n",
    "\n",
    "        loss.backward()\n",
    "        last_batch_loss = nd.mean(loss).asscalar()\n",
    "        trainer.step(x_.shape[0])\n",
    "    \n",
    "    t = time.time()\n",
    "    print([t-time1, e, last_batch_loss])\n",
    "\n",
    "time2 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47.43473291397095\n"
     ]
    }
   ],
   "source": [
    "print('time: {}'.format(time2-time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.4982897267483"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gluon_predict_iter = mx.gluon.data.DataLoader(mx.gluon.data.ArrayDataset(nd.array(X_test)), batch_size=batch_size)\n",
    "y_gluon_pred  = nd.zeros(X_test.shape[0])\n",
    "for i, (data) in enumerate(gluon_predict_iter):\n",
    "    data   = data.as_in_context(model_ctx)\n",
    "    output = gluon_model(data)\n",
    "    y_gluon_pred[i * batch_size : i * batch_size + output.shape[0]] = output[:,0]\n",
    "\n",
    "s = sklearn.metrics.mean_squared_error(y_test, y_gluon_pred.asnumpy())\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9948002789157546"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.explained_variance_score(y_test, y_gluon_pred.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, model_ctx, loss_function, init_function, optimizer = create_aux()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/cs/local/install/anaconda3-5.3.1-Linux-x86_64/envs/mxnet/lib/python3.6/site-packages/mxnet/module/base_module.py:504: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (1.0 vs. 0.00390625). Is this intended?\n",
      "  optimizer_params=optimizer_params)\n",
      "2019-02-26 06:13:10,265:root:INFO: Epoch[0] Train-mse=148.861828\n",
      "2019-02-26 06:13:10,266:root:INFO: Epoch[0] Time cost=1.031\n",
      "2019-02-26 06:13:10,321:root:INFO: Epoch[0] Validation-mse=4.877652\n",
      "2019-02-26 06:13:11,324:root:INFO: Epoch[1] Train-mse=2.899106\n",
      "2019-02-26 06:13:11,325:root:INFO: Epoch[1] Time cost=1.003\n",
      "2019-02-26 06:13:11,391:root:INFO: Epoch[1] Validation-mse=3.584615\n",
      "2019-02-26 06:13:12,378:root:INFO: Epoch[2] Train-mse=1.507336\n",
      "2019-02-26 06:13:12,379:root:INFO: Epoch[2] Time cost=0.987\n",
      "2019-02-26 06:13:12,442:root:INFO: Epoch[2] Validation-mse=3.203393\n",
      "2019-02-26 06:13:13,572:root:INFO: Epoch[3] Train-mse=0.907041\n",
      "2019-02-26 06:13:13,573:root:INFO: Epoch[3] Time cost=1.131\n",
      "2019-02-26 06:13:13,642:root:INFO: Epoch[3] Validation-mse=3.049417\n",
      "2019-02-26 06:13:14,730:root:INFO: Epoch[4] Train-mse=0.602118\n",
      "2019-02-26 06:13:14,731:root:INFO: Epoch[4] Time cost=1.089\n",
      "2019-02-26 06:13:14,794:root:INFO: Epoch[4] Validation-mse=3.011585\n",
      "2019-02-26 06:13:15,864:root:INFO: Epoch[5] Train-mse=0.436109\n",
      "2019-02-26 06:13:15,865:root:INFO: Epoch[5] Time cost=1.070\n",
      "2019-02-26 06:13:15,926:root:INFO: Epoch[5] Validation-mse=3.048699\n",
      "2019-02-26 06:13:16,920:root:INFO: Epoch[6] Train-mse=0.353177\n",
      "2019-02-26 06:13:16,921:root:INFO: Epoch[6] Time cost=0.995\n",
      "2019-02-26 06:13:16,979:root:INFO: Epoch[6] Validation-mse=3.161309\n",
      "2019-02-26 06:13:17,956:root:INFO: Epoch[7] Train-mse=0.359911\n",
      "2019-02-26 06:13:17,957:root:INFO: Epoch[7] Time cost=0.977\n",
      "2019-02-26 06:13:18,033:root:INFO: Epoch[7] Validation-mse=3.445287\n",
      "2019-02-26 06:13:19,034:root:INFO: Epoch[8] Train-mse=0.760513\n",
      "2019-02-26 06:13:19,035:root:INFO: Epoch[8] Time cost=1.002\n",
      "2019-02-26 06:13:19,108:root:INFO: Epoch[8] Validation-mse=4.351232\n",
      "2019-02-26 06:13:20,086:root:INFO: Epoch[9] Train-mse=3.391128\n",
      "2019-02-26 06:13:20,087:root:INFO: Epoch[9] Time cost=0.979\n",
      "2019-02-26 06:13:20,151:root:INFO: Epoch[9] Validation-mse=4.974088\n",
      "2019-02-26 06:13:21,278:root:INFO: Epoch[10] Train-mse=4.140797\n",
      "2019-02-26 06:13:21,279:root:INFO: Epoch[10] Time cost=1.127\n",
      "2019-02-26 06:13:21,351:root:INFO: Epoch[10] Validation-mse=4.427140\n",
      "2019-02-26 06:13:22,317:root:INFO: Epoch[11] Train-mse=2.793847\n",
      "2019-02-26 06:13:22,319:root:INFO: Epoch[11] Time cost=0.967\n",
      "2019-02-26 06:13:22,375:root:INFO: Epoch[11] Validation-mse=3.747475\n",
      "2019-02-26 06:13:23,343:root:INFO: Epoch[12] Train-mse=2.355283\n",
      "2019-02-26 06:13:23,344:root:INFO: Epoch[12] Time cost=0.968\n",
      "2019-02-26 06:13:23,408:root:INFO: Epoch[12] Validation-mse=3.855404\n",
      "2019-02-26 06:13:24,431:root:INFO: Epoch[13] Train-mse=2.160285\n",
      "2019-02-26 06:13:24,432:root:INFO: Epoch[13] Time cost=1.023\n",
      "2019-02-26 06:13:24,495:root:INFO: Epoch[13] Validation-mse=3.771260\n",
      "2019-02-26 06:13:25,507:root:INFO: Epoch[14] Train-mse=2.820612\n",
      "2019-02-26 06:13:25,508:root:INFO: Epoch[14] Time cost=1.012\n",
      "2019-02-26 06:13:25,585:root:INFO: Epoch[14] Validation-mse=7.859355\n",
      "2019-02-26 06:13:26,577:root:INFO: Epoch[15] Train-mse=3.051273\n",
      "2019-02-26 06:13:26,578:root:INFO: Epoch[15] Time cost=0.992\n",
      "2019-02-26 06:13:26,645:root:INFO: Epoch[15] Validation-mse=2.924405\n",
      "2019-02-26 06:13:27,676:root:INFO: Epoch[16] Train-mse=2.630089\n",
      "2019-02-26 06:13:27,677:root:INFO: Epoch[16] Time cost=1.032\n",
      "2019-02-26 06:13:27,744:root:INFO: Epoch[16] Validation-mse=4.457952\n",
      "2019-02-26 06:13:28,811:root:INFO: Epoch[17] Train-mse=2.259041\n",
      "2019-02-26 06:13:28,812:root:INFO: Epoch[17] Time cost=1.068\n",
      "2019-02-26 06:13:28,880:root:INFO: Epoch[17] Validation-mse=3.203327\n",
      "2019-02-26 06:13:29,945:root:INFO: Epoch[18] Train-mse=2.751709\n",
      "2019-02-26 06:13:29,946:root:INFO: Epoch[18] Time cost=1.065\n",
      "2019-02-26 06:13:30,027:root:INFO: Epoch[18] Validation-mse=2.751668\n",
      "2019-02-26 06:13:31,024:root:INFO: Epoch[19] Train-mse=2.580007\n",
      "2019-02-26 06:13:31,025:root:INFO: Epoch[19] Time cost=0.997\n",
      "2019-02-26 06:13:31,091:root:INFO: Epoch[19] Validation-mse=2.524739\n"
     ]
    }
   ],
   "source": [
    "sym_model = create_sym_model()\n",
    "\n",
    "sym_model_module = mx.mod.Module(symbol = sym_model, data_names = ['data'], label_names = ['lin_reg_label'], context = model_ctx)\n",
    "\n",
    "freq = int((len(X_train) * epochs / batch_size) // 10)\n",
    "batch_end_callback = mx.callback.Speedometer(batch_size, frequent=freq, auto_reset=False)\n",
    "\n",
    "time1 = time.time()\n",
    "\n",
    "sym_model_module.fit(sym_train_iter, \n",
    "                     sym_valid_iter,\n",
    "                     optimizer=optimizer,\n",
    "                     initializer=init_function,\n",
    "                     num_epoch=epochs,\n",
    "                     eval_metric='mse',\n",
    "                     batch_end_callback=batch_end_callback\n",
    "                    )\n",
    "time2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.861199855804443\n"
     ]
    }
   ],
   "source": [
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5199532238884363"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sym_pred = sym_model_module.predict(sym_valid_iter)\n",
    "s = sklearn.metrics.mean_squared_error(y_test, y_sym_pred.asnumpy())\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974339473895943"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.explained_variance_score(y_test, y_sym_pred.asnumpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
