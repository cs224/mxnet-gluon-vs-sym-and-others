{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christian Schuhegger \n",
      "last updated: 2019-02-27 \n",
      "\n",
      "CPython 3.6.8\n",
      "IPython 7.3.0\n",
      "\n",
      "numpy 1.14.6\n",
      "scipy 1.2.0\n",
      "pandas 0.24.1\n",
      "matplotlib 3.0.2\n",
      "seaborn 0.9.0\n",
      "mxnet 1.3.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Christian Schuhegger' -u -d -v -p numpy,scipy,pandas,matplotlib,seaborn,mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, scipy, scipy.stats as stats, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import sklearn, sklearn.pipeline, sklearn.model_selection, sklearn.preprocessing\n",
    "import logging, time, datetime, tqdm\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, autograd, metric\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "# pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "np.set_printoptions(edgeitems=10)\n",
    "np.set_printoptions(linewidth=1000)\n",
    "np.set_printoptions(suppress=True)\n",
    "np.core.arrayprint._line_width = 180\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "from IPython.display import display_html\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        if type(df) == np.ndarray:\n",
    "            df = pd.DataFrame(df)\n",
    "        html_str+=df.to_html()\n",
    "    html_str = html_str.replace('table','table style=\"display:inline\"')\n",
    "    # print(html_str)\n",
    "    display_html(html_str,raw=True)\n",
    "\n",
    "CSS = \"\"\"\n",
    ".output {\n",
    "    flex-direction: row;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def display_graphs_side_by_side(*args):\n",
    "    html_str='<table><tr>'\n",
    "    for g in args:\n",
    "        html_str += '<td>'\n",
    "        html_str += g._repr_svg_()\n",
    "        html_str += '</td>'\n",
    "    html_str += '</tr></table>'\n",
    "    display_html(html_str,raw=True)\n",
    "    \n",
    "\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s:%(name)s:%(levelname)s: %(message)s')\n",
    "log = logging.getLogger('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_in       = 1000\n",
    "N_subjects = 260 * 10 # 100000\n",
    "N_subjects = 100000\n",
    "W = stats.norm(loc=0, scale=1).rvs(size=(2,N_in), random_state=np.random.RandomState(42))\n",
    "X = stats.norm(loc=0, scale=1).rvs(size=(N_subjects,N_in), random_state=np.random.RandomState(43))\n",
    "y = np.sum(W[1:,:] * X + W[0,:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000,), (100000, 1000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100000.000000\n",
       "mean         19.234805\n",
       "std          31.516783\n",
       "min        -147.380827\n",
       "25%          -2.102370\n",
       "50%          19.273695\n",
       "75%          40.475011\n",
       "max         147.253509\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gluon_iter(x_in, y_in, batch_size=256):\n",
    "    x_nd = nd.array(x_in)\n",
    "    y_nd = nd.array(y_in)\n",
    "    dataset = mx.gluon.data.ArrayDataset(x_nd, y_nd)\n",
    "\n",
    "    itr = mx.gluon.data.DataLoader(dataset, batch_size = batch_size, shuffle = None)# , last_batch = 'rollover'\n",
    "    return itr\n",
    "\n",
    "def to_sym_iter(x_in, y_in, batch_size=256):\n",
    "    itr = mx.io.NDArrayIter(x_in, y_in, batch_size, shuffle=None , label_name='lin_reg_label')\n",
    "    return itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIterLoader():\n",
    "    def __init__(self, data_iter):\n",
    "        self.data_iter = data_iter\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.data_iter.reset()\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        batch = self.data_iter.__next__()\n",
    "        assert len(batch.data) == len(batch.label) == 1\n",
    "        # print('len(batch_data): {}; batch.data[0].shape: {}'.format(len(batch.data), batch.data[0].shape))\n",
    "        data = batch.data[0]\n",
    "        label = batch.label[0]\n",
    "        return data, label\n",
    "\n",
    "    def next(self):\n",
    "        return self.__next__() # for Python 2\n",
    "\n",
    "# See:\n",
    "#  Appendix: Upgrading from Module DataIter to Gluon DataLoader\n",
    "#  https://mxnet.incubator.apache.org/versions/master/tutorials/gluon/datasets.html\n",
    "batch_size=256\n",
    "# gluon_train_iter = to_gluon_iter(X_train, y_train, batch_size=batch_size)\n",
    "# gluon_valid_iter = to_gluon_iter(X_test , y_test, batch_size=batch_size)\n",
    "\n",
    "sym_train_iter = to_sym_iter(X_train, y_train, batch_size=batch_size)\n",
    "sym_valid_iter  = to_sym_iter(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "gluon_train_iter = DataIterLoader(sym_train_iter)\n",
    "gluon_valid_iter = DataIterLoader(sym_valid_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aux():\n",
    "    epochs=20\n",
    "    model_ctx=mx.cpu()\n",
    "    loss_function = mx.gluon.loss.L2Loss()\n",
    "    init_function = mx.init.Xavier()\n",
    "    optimizer     = mx.optimizer.Adam()\n",
    "    return epochs, model_ctx, loss_function, init_function, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gluon_model():\n",
    "    ACTIVATION = 'relu'\n",
    "    net = mx.gluon.nn.HybridSequential(prefix='MLP_')\n",
    "    with net.name_scope():\n",
    "        net.add(\n",
    "            mx.gluon.nn.Dense(300, activation=ACTIVATION, prefix='fc-1_'),\n",
    "            mx.gluon.nn.Dense(100, activation=ACTIVATION, prefix='fc-2_'),\n",
    "            mx.gluon.nn.Dense(1 , activation=None       , prefix='predictions')\n",
    "        )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sym_model():\n",
    "    ACTIVATION = 'relu'\n",
    "\n",
    "    data = mx.sym.Variable('data')\n",
    "    Y    = mx.sym.Variable('lin_reg_label')\n",
    "    fc1  = mx.sym.FullyConnected(data, name='fc1', num_hidden=300)\n",
    "    act1 = mx.sym.Activation(fc1, name='relu1', act_type=ACTIVATION)\n",
    "    fc2  = mx.sym.FullyConnected(act1, name='fc2', num_hidden=100)\n",
    "    act2 = mx.sym.Activation(fc2, name='relu2', act_type=ACTIVATION)\n",
    "    fc3  = mx.sym.FullyConnected(act2, name='fc3', num_hidden=1)\n",
    "    lro  = mx.sym.LinearRegressionOutput(data=fc3, label=Y, name=\"lro\")\n",
    "    \n",
    "    return lro    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, model_ctx, loss_function, init_function, optimizer = create_aux()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.002150297164917, 0, 2.3317626]\n",
      "[2.068141460418701, 1, 0.8200017]\n",
      "[3.078101634979248, 2, 0.41898423]\n",
      "[4.136557340621948, 3, 0.25386566]\n",
      "[5.115137577056885, 4, 0.17628984]\n",
      "[6.105294942855835, 5, 0.13901676]\n",
      "[7.126128673553467, 6, 0.12758017]\n",
      "[8.11776351928711, 7, 0.19650489]\n",
      "[9.117296934127808, 8, 1.0679522]\n",
      "[10.12504529953003, 9, 3.6427248]\n",
      "[11.126052141189575, 10, 1.3626083]\n",
      "[12.109097480773926, 11, 0.6898772]\n",
      "[13.0963454246521, 12, 1.2826223]\n",
      "[14.081398725509644, 13, 1.0957555]\n",
      "[15.096967458724976, 14, 1.1497743]\n",
      "[16.069961309432983, 15, 1.9431003]\n",
      "[17.076117515563965, 16, 1.5676603]\n",
      "[18.11342215538025, 17, 2.5785687]\n",
      "[19.103195428848267, 18, 2.671261]\n",
      "[20.170690536499023, 19, 2.2330596]\n"
     ]
    }
   ],
   "source": [
    "sym_train_iter = to_sym_iter(X_train, y_train, batch_size=batch_size)\n",
    "sym_valid_iter  = to_sym_iter(X_test, y_test, batch_size=batch_size)\n",
    "gluon_model = create_gluon_model()\n",
    "# gluon_model.hybridize()\n",
    "gluon_model.hybridize(static_shape=True, static_alloc=True)\n",
    "gluon_model.collect_params().initialize(init_function, ctx=model_ctx)\n",
    "\n",
    "trainer = gluon.Trainer(gluon_model.collect_params(), optimizer)\n",
    "\n",
    "nr_batches = len(X_train) // batch_size\n",
    "total = epochs * (nr_batches + 1)\n",
    "\n",
    "time1 = time.time()\n",
    "for e in range(epochs):\n",
    "    for i, (x_, y_) in enumerate(gluon_train_iter):\n",
    "        x_ = x_.as_in_context(model_ctx)\n",
    "        y_ = y_.as_in_context(model_ctx)\n",
    "        with autograd.record():\n",
    "            output = gluon_model(x_)\n",
    "            loss = loss_function(output, y_)\n",
    "\n",
    "        loss.backward()\n",
    "        last_batch_loss = nd.mean(loss).asscalar()\n",
    "        trainer.step(x_.shape[0])\n",
    "    \n",
    "    t = time.time()\n",
    "    print([t-time1, e, last_batch_loss])\n",
    "\n",
    "time2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.17090630531311\n"
     ]
    }
   ],
   "source": [
    "print('time: {}'.format(time2-time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.396654576967551"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gluon_predict_iter = mx.gluon.data.DataLoader(mx.gluon.data.ArrayDataset(nd.array(X_test)), batch_size=batch_size)\n",
    "y_gluon_pred  = nd.zeros(X_test.shape[0])\n",
    "for i, (data) in enumerate(gluon_predict_iter):\n",
    "    data   = data.as_in_context(model_ctx)\n",
    "    output = gluon_model(data)\n",
    "    y_gluon_pred[i * batch_size : i * batch_size + output.shape[0]] = output[:,0]\n",
    "\n",
    "s = sklearn.metrics.mean_squared_error(y_test, y_gluon_pred.asnumpy())\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9955717688296912"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.explained_variance_score(y_test, y_gluon_pred.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, model_ctx, loss_function, init_function, optimizer = create_aux()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/cs/local/install/anaconda3-5.3.1-Linux-x86_64/envs/mxnet/lib/python3.6/site-packages/mxnet/module/base_module.py:504: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (1.0 vs. 0.00390625). Is this intended?\n",
      "  optimizer_params=optimizer_params)\n",
      "2019-02-27 11:29:38,909:root:INFO: Epoch[0] Train-mse=148.861828\n",
      "2019-02-27 11:29:38,910:root:INFO: Epoch[0] Time cost=1.035\n",
      "2019-02-27 11:29:38,975:root:INFO: Epoch[0] Validation-mse=4.877652\n",
      "2019-02-27 11:29:40,034:root:INFO: Epoch[1] Train-mse=2.899106\n",
      "2019-02-27 11:29:40,035:root:INFO: Epoch[1] Time cost=1.058\n",
      "2019-02-27 11:29:40,115:root:INFO: Epoch[1] Validation-mse=3.584615\n",
      "2019-02-27 11:29:41,233:root:INFO: Epoch[2] Train-mse=1.507336\n",
      "2019-02-27 11:29:41,234:root:INFO: Epoch[2] Time cost=1.119\n",
      "2019-02-27 11:29:41,310:root:INFO: Epoch[2] Validation-mse=3.203393\n",
      "2019-02-27 11:29:42,440:root:INFO: Epoch[3] Train-mse=0.907041\n",
      "2019-02-27 11:29:42,441:root:INFO: Epoch[3] Time cost=1.130\n",
      "2019-02-27 11:29:42,505:root:INFO: Epoch[3] Validation-mse=3.049417\n",
      "2019-02-27 11:29:43,548:root:INFO: Epoch[4] Train-mse=0.602118\n",
      "2019-02-27 11:29:43,549:root:INFO: Epoch[4] Time cost=1.043\n",
      "2019-02-27 11:29:43,607:root:INFO: Epoch[4] Validation-mse=3.011585\n",
      "2019-02-27 11:29:44,640:root:INFO: Epoch[5] Train-mse=0.436109\n",
      "2019-02-27 11:29:44,641:root:INFO: Epoch[5] Time cost=1.033\n",
      "2019-02-27 11:29:44,723:root:INFO: Epoch[5] Validation-mse=3.048699\n",
      "2019-02-27 11:29:45,755:root:INFO: Epoch[6] Train-mse=0.353177\n",
      "2019-02-27 11:29:45,756:root:INFO: Epoch[6] Time cost=1.031\n",
      "2019-02-27 11:29:45,828:root:INFO: Epoch[6] Validation-mse=3.161309\n",
      "2019-02-27 11:29:46,855:root:INFO: Epoch[7] Train-mse=0.359911\n",
      "2019-02-27 11:29:46,856:root:INFO: Epoch[7] Time cost=1.027\n",
      "2019-02-27 11:29:46,922:root:INFO: Epoch[7] Validation-mse=3.445287\n",
      "2019-02-27 11:29:47,975:root:INFO: Epoch[8] Train-mse=0.760513\n",
      "2019-02-27 11:29:47,976:root:INFO: Epoch[8] Time cost=1.054\n",
      "2019-02-27 11:29:48,044:root:INFO: Epoch[8] Validation-mse=4.351232\n",
      "2019-02-27 11:29:49,061:root:INFO: Epoch[9] Train-mse=3.391128\n",
      "2019-02-27 11:29:49,062:root:INFO: Epoch[9] Time cost=1.017\n",
      "2019-02-27 11:29:49,132:root:INFO: Epoch[9] Validation-mse=4.974088\n",
      "2019-02-27 11:29:50,216:root:INFO: Epoch[10] Train-mse=4.140797\n",
      "2019-02-27 11:29:50,217:root:INFO: Epoch[10] Time cost=1.084\n",
      "2019-02-27 11:29:50,295:root:INFO: Epoch[10] Validation-mse=4.427140\n",
      "2019-02-27 11:29:51,438:root:INFO: Epoch[11] Train-mse=2.793847\n",
      "2019-02-27 11:29:51,439:root:INFO: Epoch[11] Time cost=1.143\n",
      "2019-02-27 11:29:51,518:root:INFO: Epoch[11] Validation-mse=3.747475\n",
      "2019-02-27 11:29:52,573:root:INFO: Epoch[12] Train-mse=2.355283\n",
      "2019-02-27 11:29:52,574:root:INFO: Epoch[12] Time cost=1.055\n",
      "2019-02-27 11:29:52,650:root:INFO: Epoch[12] Validation-mse=3.855404\n",
      "2019-02-27 11:29:53,688:root:INFO: Epoch[13] Train-mse=2.160285\n",
      "2019-02-27 11:29:53,689:root:INFO: Epoch[13] Time cost=1.038\n",
      "2019-02-27 11:29:53,749:root:INFO: Epoch[13] Validation-mse=3.771260\n",
      "2019-02-27 11:29:54,813:root:INFO: Epoch[14] Train-mse=2.820612\n",
      "2019-02-27 11:29:54,813:root:INFO: Epoch[14] Time cost=1.064\n",
      "2019-02-27 11:29:54,886:root:INFO: Epoch[14] Validation-mse=7.859355\n",
      "2019-02-27 11:29:55,929:root:INFO: Epoch[15] Train-mse=3.051273\n",
      "2019-02-27 11:29:55,929:root:INFO: Epoch[15] Time cost=1.043\n",
      "2019-02-27 11:29:56,011:root:INFO: Epoch[15] Validation-mse=2.924405\n",
      "2019-02-27 11:29:57,195:root:INFO: Epoch[16] Train-mse=2.630089\n",
      "2019-02-27 11:29:57,196:root:INFO: Epoch[16] Time cost=1.183\n",
      "2019-02-27 11:29:57,258:root:INFO: Epoch[16] Validation-mse=4.457952\n",
      "2019-02-27 11:29:58,285:root:INFO: Epoch[17] Train-mse=2.259041\n",
      "2019-02-27 11:29:58,285:root:INFO: Epoch[17] Time cost=1.027\n",
      "2019-02-27 11:29:58,366:root:INFO: Epoch[17] Validation-mse=3.203327\n",
      "2019-02-27 11:29:59,379:root:INFO: Epoch[18] Train-mse=2.751709\n",
      "2019-02-27 11:29:59,381:root:INFO: Epoch[18] Time cost=1.014\n",
      "2019-02-27 11:29:59,451:root:INFO: Epoch[18] Validation-mse=2.751668\n",
      "2019-02-27 11:30:00,499:root:INFO: Epoch[19] Train-mse=2.580007\n",
      "2019-02-27 11:30:00,500:root:INFO: Epoch[19] Time cost=1.048\n",
      "2019-02-27 11:30:00,576:root:INFO: Epoch[19] Validation-mse=2.524739\n"
     ]
    }
   ],
   "source": [
    "sym_model = create_sym_model()\n",
    "\n",
    "sym_model_module = mx.mod.Module(symbol = sym_model, data_names = ['data'], label_names = ['lin_reg_label'], context = model_ctx)\n",
    "\n",
    "freq = int((len(X_train) * epochs / batch_size) // 10)\n",
    "batch_end_callback = mx.callback.Speedometer(batch_size, frequent=freq, auto_reset=False)\n",
    "\n",
    "time1 = time.time()\n",
    "\n",
    "sym_model_module.fit(sym_train_iter, \n",
    "                     sym_valid_iter,\n",
    "                     optimizer=optimizer,\n",
    "                     initializer=init_function,\n",
    "                     num_epoch=epochs,\n",
    "                     eval_metric='mse',\n",
    "                     batch_end_callback=batch_end_callback\n",
    "                    )\n",
    "time2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.70542311668396\n"
     ]
    }
   ],
   "source": [
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5199532238884363"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sym_pred = sym_model_module.predict(sym_valid_iter)\n",
    "s = sklearn.metrics.mean_squared_error(y_test, y_sym_pred.asnumpy())\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974339473895943"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.explained_variance_score(y_test, y_sym_pred.asnumpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
